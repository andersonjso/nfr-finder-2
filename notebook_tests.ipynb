{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_analyze = ['number_of_merged_prs', 'experience_in_days', 'avg_size_of_commits', 'mean_time_between_merged_prs', \n",
    "           'number_of_pull_requests_opened', 'pulls_opened', 'number_of_commits', 'pulls_closed', 'mean_discussion_duration',\n",
    "          'mean_time_between_comments', 'mean_words', 'total_words', 'number_of_comments', 'lines_revised', 'number_files_revised',\n",
    "          'number_modules_revised', 'number_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "def load_files(system):\n",
    "    pull_file_path = f'data/metrics/{system}_info_devs.json'\n",
    "    refactorings_file_path = f'data/metrics/refactorings_{system}.json'\n",
    "    metrics = f'data/metrics/metrics_output.json'\n",
    "\n",
    "    with open(pull_file_path) as json_input:\n",
    "        dev_info = json.load(json_input)\n",
    "\n",
    "    with open(refactorings_file_path) as json_input:\n",
    "        refactorings_info = json.load(json_input)\n",
    "\n",
    "    with open(metrics) as json_input:\n",
    "        metrics = json.load(json_input)\n",
    "        \n",
    "    return dev_info, refactorings_info, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dict_quartiles(system, refactorings_info, users_metrics):\n",
    "    dict_metrics = {}\n",
    "\n",
    "    for user in users_metrics:\n",
    "        for metric in metrics_to_analyze:\n",
    "            if metric in user:\n",
    "                if metric in dict_metrics:\n",
    "                    dict_metrics[metric].append(user[metric])\n",
    "                else:\n",
    "                    dict_metrics[metric] = []\n",
    "                    dict_metrics[metric].append(user[metric])\n",
    "    \n",
    "    quartiles_metrics = {}\n",
    "    for metric in dict_metrics:\n",
    "        quartiles_metrics[metric] = {}\n",
    "\n",
    "        quartiles_metrics[metric][\"1st\"] = np.percentile(list(set(dict_metrics[metric])), 25)\n",
    "        quartiles_metrics[metric][\"median\"] = np.percentile(list(set(dict_metrics[metric])), 50)\n",
    "        quartiles_metrics[metric][\"3rd\"] = np.percentile(list(set(dict_metrics[metric])), 75)\n",
    "        \n",
    "    all_refs = []\n",
    "    for dev_name in refactorings_info:\n",
    "        dev = refactorings_info[dev_name]\n",
    "        all_refs.append(dev['num_refactorings'])\n",
    "\n",
    "    quartiles_metrics['refactorings'] = {}\n",
    "    quartiles_metrics['refactorings'][\"1st\"] = np.percentile(list(set(all_refs)), 25)\n",
    "    quartiles_metrics['refactorings'][\"median\"] = np.percentile(list(set(all_refs)), 50)\n",
    "    quartiles_metrics['refactorings'][\"3rd\"] = np.percentile(list(set(all_refs)), 75)\n",
    "    \n",
    "    return quartiles_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_quartile(dict_quartiles, metric_name, value_metric):\n",
    "    if value_metric >= quartiles_metrics[metric_name]['3rd']:\n",
    "        return \"HIGH\"\n",
    "    elif value_metric <= quartiles_metrics[metric_name]['1st']:\n",
    "        return \"LOW\"\n",
    "    else:\n",
    "        return \"MEDIUM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_quartiles_metrics(user_metrics, metrics):\n",
    "    user_quartiles_metrics = {}\n",
    "    for user in users_metrics:\n",
    "        username = user['username']\n",
    "        user_quartiles_metrics[username] = {}\n",
    "        for metric in metrics:\n",
    "            if metric in user:\n",
    "                user_quartiles_metrics[username][metric] = get_group_quartile(dict_quartiles=quartiles_metrics, \n",
    "                                                                          metric_name=metric, \n",
    "                                                                          value_metric=user[metric])\n",
    "            else:\n",
    "                user_quartiles_metrics[username][metric] = \"NONE\"\n",
    "\n",
    "    for user in refactorings_info:\n",
    "        if user in user_quartiles_metrics:\n",
    "            user_quartiles_metrics[user]['refactorings'] = get_group_quartile(dict_quartiles=quartiles_metrics, \n",
    "                                                                              metric_name='refactorings', \n",
    "                                                                              value_metric=refactorings_info[user]['num_refactorings'])\n",
    "        else:\n",
    "            user_quartiles_metrics[user] = {}\n",
    "            user_quartiles_metrics[user]['refactorings'] = get_group_quartile(dict_quartiles=quartiles_metrics, \n",
    "                                                                              metric_name='refactorings', \n",
    "                                                                              value_metric=refactorings_info[user]['num_refactorings'])\n",
    "    \n",
    "    return user_quartiles_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups_by_nfr(nfr):\n",
    "    list_participates = []\n",
    "    list_commited = []\n",
    "    list_opened = []\n",
    "    list_reviewed = []\n",
    "    list_commented = []\n",
    "\n",
    "    for current_dev in dev_info:\n",
    "        dev = dev_info[current_dev]\n",
    "        \n",
    "        if current_dev:\n",
    "            if dev[f'participates_{nfr}_high']:\n",
    "                list_participates.append(current_dev)\n",
    "            if dev[f'commited_{nfr}_high']:\n",
    "                list_commited.append(current_dev)\n",
    "            if dev[f'opened_discussion_{nfr}_high']:\n",
    "                list_opened.append(current_dev)\n",
    "            if dev[f'commented_{nfr}_high']:\n",
    "                list_commented.append(current_dev)\n",
    "            if dev[f'reviewed_{nfr}_high']:\n",
    "               list_reviewed.append(current_dev)\n",
    "\n",
    "    #print (\"Participates:\", list_participates)\n",
    "    print (\"Commits:\", list_commited)\n",
    "    print (\"Opens:\", list_opened)\n",
    "    print (\"Reviews:\", list_reviewed)\n",
    "    print (\"Comments:\", list_commented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_whole_system(system):\n",
    "    print (f\"Analyzing {system}\")\n",
    "    dev_info, refactorings_info, metrics = load_files(system)\n",
    "    print (f\"Dev Info: {list(dev_info.keys())[0]}\")\n",
    "    print (f\"Ref Info: {list(refactorings_info.keys())[0]}\")\n",
    "\n",
    "    metrics_current_system = metrics[system]\n",
    "    users_metrics = metrics_current_system['user_metrics']\n",
    "    print (f\"User Info: {list(users_metrics[0]['username'])}\")\n",
    "    \n",
    "    quartiles_metrics = define_dict_quartiles(system, refactorings_info, users_metrics)\n",
    "    user_quartiles_metrics = get_user_quartiles_metrics(users_metrics, metrics_to_analyze)\n",
    "    \n",
    "    get_groups_by_nfr(\"security\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dev_info, refactorings_info, metrics \u001b[38;5;241m=\u001b[39m load_files(\u001b[43msystem\u001b[49m)\n\u001b[0;32m      2\u001b[0m metrics_current_system \u001b[38;5;241m=\u001b[39m metrics[system]\n\u001b[0;32m      3\u001b[0m users_metrics \u001b[38;5;241m=\u001b[39m metrics_current_system[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'system' is not defined"
     ]
    }
   ],
   "source": [
    "dev_info, refactorings_info, metrics = load_files(system)\n",
    "metrics_current_system = metrics[system]\n",
    "users_metrics = metrics_current_system['user_metrics']\n",
    "quartiles_metrics = define_dict_quartiles(system, refactorings_info, users_metrics)\n",
    "\n",
    "json_formatted_str = json.dumps(quartiles_metrics, indent=2)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_quartiles_metrics = get_user_quartiles_metrics(users_metrics, metrics_to_analyze)\n",
    "json_formatted_str = json.dumps(user_quartiles_metrics, indent=2)\n",
    "print (system)\n",
    "print(json_formatted_str)\n",
    "\n",
    "with open(f\"data/metrics/groups_users_metrics_{system}.json\", \"w\") as write_file:\n",
    "    json.dump(user_quartiles_metrics, write_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"security\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"robustness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"robustness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"maintainability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups_by_nfr(\"performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> All NFRs </h3>\n",
    "\n",
    "- jgrandja: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- jzheaux: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- rwinch: Commits, Reviews, Comments\n",
    "\n",
    "- eleftherias: Commits, Reviews, eleftherias\n",
    "\n",
    "- marcusdacoregio: Opens\n",
    "\n",
    "- evgeniycheban: Reviews\n",
    "\n",
    "- ch4mpy: Reviews\n",
    "\n",
    "- Buzzardo: Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Security </h3>\n",
    "\n",
    "- jgrandja: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- jzheaux: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- rwinch: Commits, Reviews, Comments\n",
    "\n",
    "- evgeniycheban: Reviews\n",
    "\n",
    "- rh-id: Reviews [Não aparecia no geral]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Robustness </h3>\n",
    "\n",
    "- jgrandja: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- jzheaux: Reviews, Comments\n",
    "\n",
    "- rwinch: Reviews, Comments\n",
    "\n",
    "- DevDengChao: Commits\n",
    "\n",
    "- fhanik: fhanik\n",
    "\n",
    "- kostya05983: Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Maintainability </h3>\n",
    "\n",
    "- jgrandja: Opens, Comments\n",
    "\n",
    "- jzheaux: Commits, Reviews, Comments\n",
    "\n",
    "- rwinch: Commits, Reviews, Comments\n",
    "          \n",
    "- eleftherias: Commits, Reviews     \n",
    "\n",
    "- marcusdacoregio: Commits\n",
    "\n",
    "- evgeniycheban: Reviews\n",
    "\n",
    "- ch4mpy: Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4147502435.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [14]\u001b[1;36m\u001b[0m\n\u001b[1;33m    <h3> Performance </h3>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h3> Performance </h3>\n",
    "Opens: ['ThomasVitale', 'larsgrefer', 'bagyoni', 'aj-jaswanth', 'bstuder', 'robotmrv', '20fps', 'stsypanov', 'avpoloz', 'miremond', 'william-tran', 'dratler', 'sedran']\n",
    "Reviews: ['rwinch', 'eleftherias', 'dratler']\n",
    "Comments: ['rwinch', 'jzheaux', 'miremond']\n",
    "\n",
    "- jgrandja: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- jzheaux: Commits, Opens, Reviews, Comments\n",
    "\n",
    "- rwinch: Commits, Reviews, Comments\n",
    "\n",
    "- evgeniycheban: Reviews\n",
    "\n",
    "- rh-id: Reviews [Não aparecia no geral]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jgrandja, jzheaux, rwinch\n",
    "data_jgrandja = json.dumps(user_quartiles_metrics['jgrandja'], indent=2)\n",
    "print (data_jgrandja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jzheaux = json.dumps(user_quartiles_metrics['jzheaux'], indent=2)\n",
    "print (data_jzheaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rwinch = json.dumps(user_quartiles_metrics['rwinch'], indent=2)\n",
    "print (data_rwinch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Análise Spring Framework </h1>\n",
    "\n",
    "<h3> All NFRs </h3>\n",
    "\n",
    "- philwebb: Commits\n",
    "\n",
    "- diguage: Commits\n",
    "\n",
    "- chenqimiao: Commits, Opens\n",
    "\n",
    "- bclozel: Opens, Reviews\n",
    "\n",
    "- dreis2211: Opens\n",
    "\n",
    "- diguage: Opens\n",
    "\n",
    "- sbrannen: Reviews\n",
    "\n",
    "- poutsma: Reviews\n",
    "\n",
    "- rstoyanchev: Comments\n",
    "\n",
    "- sbrannen: Comments\n",
    "\n",
    "- jhoeller: Comments\n",
    "\n",
    "<h3> Security </h3>\n",
    "\n",
    "- rstoyanchev: Comments\n",
    "\n",
    "\n",
    "<h3> Maintainability </h3>\n",
    "\n",
    "- diguage: Opens, Commits\n",
    "\n",
    "- chenqimiao: Opens, Commits\n",
    "\n",
    "- sbrannen: Reviews, Comments\n",
    "\n",
    "- poutsma: Reviews\n",
    "\n",
    "- rstoyanchev: Comments\n",
    "\n",
    "<h3> Robustness </h3>\n",
    "\n",
    "- loiclefevre: Commits\n",
    "\n",
    "- ShaoqiangLu: Commits\n",
    "\n",
    "- xCubeSource: Commits\n",
    "\n",
    "- bclozel: Opens\n",
    "\n",
    "- sbrannen: Reviews, Comments\n",
    "\n",
    "- rstoyanchev: Comments\n",
    "\n",
    "<h3> Performance </h3>\n",
    "\n",
    "- philwebb: Commits\n",
    "\n",
    "- dreis2211: Opens\n",
    "\n",
    "- stsypanov: Opens\n",
    "\n",
    "- bclozel: Reviews\n",
    "\n",
    "- poutsma: Reviews\n",
    "\n",
    "- mentallurg: Reviews\n",
    "\n",
    "- rstoyanchev: Comments\n",
    "\n",
    "- sbrannen: Comments\n",
    "\n",
    "- jhoeller: Comments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rstoyanchev: \n",
    "    - Comments (All, Security, Rob, Per)\n",
    "\n",
    "- sbrannen: \n",
    "    - Comments (All, Maint, Rob, Perf)\n",
    "    - Reviews (All, Maint, Rob)\n",
    "\n",
    "\n",
    "- philwebb: Commits (All, Per)\n",
    "\n",
    "- diguage: \n",
    "    Commits (All, Maint)\n",
    "    Opens (Maint)\n",
    "\n",
    "- chenqimiao: Commits, Opens (All, Maint)\n",
    "\n",
    "- bclozel: \n",
    "    Opens (All, Rob)\n",
    "    Reviews (All, Per)\n",
    "\n",
    "- dreis2211: Opens (All)\n",
    "\n",
    "- diguage: Opens (All)\n",
    "\n",
    "- sbrannen: Reviews (All)\n",
    "\n",
    "- poutsma: Reviews (All)\n",
    "\n",
    "- jhoeller: Comments (All, Per)\n",
    "        \n",
    "- poutsma: Reviews (Maint, Per)\n",
    "    \n",
    "- loiclefevre: Commits (Rob)\n",
    "\n",
    "- ShaoqiangLu: Commits (Rob)\n",
    "\n",
    "- xCubeSource: Commits (Rob)\n",
    "\n",
    "- dreis2211: Opens (Per)\n",
    "\n",
    "- stsypanov: Opens (Per)\n",
    "\n",
    "- mentallurg: Reviews (Per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
